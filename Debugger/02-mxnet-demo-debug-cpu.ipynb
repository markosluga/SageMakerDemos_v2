{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SageMaker debugger to visualise model training in real time\n",
    "\n",
    "**Before starting the lab please ensure the notegbook is deployed in <span style=\"color:red\">us-west-2</span> and the Kernel is selected as <span style=\"color:red\">MXNet 1.8 Python 3.7 CPU Optimized</span>**\n",
    "\n",
    "This notebook will train a convolutional autoencoder model on [MNIST dataset of handwritten digits](http://yann.lecun.com/exdb/mnist/). When running training through a convolutional model, the layers are hidden from sight. In this demo we will use SageMaker Debugger to better understand how well the autoencoder is learning. We can check if the model is training well by checking:\n",
    "\n",
    "1. Reconstructed images (autoencoder output): \n",
    "\n",
    "The autoencoder is able to learn how to decompose data (in our case, images) into fairly small bits of data, and then using that representation, reconstruct the original data as closely as it can to the original. This visualisation helps us understand how much of the original data has been lost while the autoencoder \n",
    "\n",
    "2. The t-Distributed Stochastic Neighbor Embedding (t-SNE) of the latent variables: \n",
    "\n",
    "The t-SNE map will plot the training results into a 2-dimensional representation of clustered data. Eachcluster represents on MNIST class - a number from 0 to 9. As the training progresses the autoencoder becomes better in separating those classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MXNet autoencoder model in Amazon SageMaker with debugger \n",
    "Before starting the SageMaker training job, we need to install some libraries. We will use `smdebug` library to read, filter and analyze raw tensors that are stored in Amazon S3. We install `seaborn` library that will be used later on to plot t-Distributed Stochastic Neighbor Embedding (t-SNE) of the latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smdebug --quiet\n",
    "!pip install seaborn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training\n",
    "\n",
    "The following code will define the MXNet estimator and run a training job. Notice that the estimatoor has the debugger hook configuration (debugger_hook_config=...). Also notice that the model training is implemented in the entry point script `autoencoder_mnist.py` provided in this demo. \n",
    "\n",
    "We can access the tensors from S3 once the training job is in status Training or Completed. **This should take about 2-3 minutes.** During this time, we can inspect the training job in the [SageMaker Managemnt Console](https://us-west-2.console.aws.amazon.com/sagemaker/home?region=us-west-2#/jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker.debugger import DebuggerHookConfig, CollectionConfig\n",
    "import time\n",
    "\n",
    "#Set up the training S3 bucket:\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "LOCATION_IN_BUCKET = \"smdebug-autoencoder-example\"\n",
    "\n",
    "s3_bucket_for_tensors = \"s3://{BUCKET_NAME}/{LOCATION_IN_BUCKET}\".format(\n",
    "    BUCKET_NAME=BUCKET_NAME, LOCATION_IN_BUCKET=LOCATION_IN_BUCKET\n",
    ")\n",
    "\n",
    "#MXNet estimator and the debugger hook configuration:\n",
    "\n",
    "estimator = MXNet(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=\"mxnet\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    volume_size=400,\n",
    "    source_dir=\".\",\n",
    "    entry_point=\"autoencoder_mnist.py\",\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=s3_bucket_for_tensors,\n",
    "        collection_configs=[\n",
    "            CollectionConfig(\n",
    "                name=\"all\",\n",
    "                parameters={\n",
    "                    \"include_regex\": \".*convolutionalautoencoder0_hybridsequential0_dense0_output_0|.*convolutionalautoencoder0_input_1|.*loss\",\n",
    "                    \"save_interval\": \"10\",\n",
    "                },\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "#Start the training job:\n",
    "\n",
    "estimator.fit(wait=False)\n",
    "\n",
    "#Wait for the job to start training and creating tensors in the S3 bucket:\n",
    "\n",
    "path = estimator.latest_job_debugger_artifacts_path()\n",
    "job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=job_name)\n",
    "\n",
    "\n",
    "if description[\"TrainingJobStatus\"] != \"Completed\":\n",
    "    while description[\"SecondaryStatus\"] not in {\"Training\", \"Completed\"}:\n",
    "        description = client.describe_training_job(TrainingJobName=job_name)\n",
    "        primary_status = description[\"TrainingJobStatus\"]\n",
    "        secondary_status = description[\"SecondaryStatus\"]\n",
    "        print(\n",
    "            \"Current job status: [PrimaryStatus: {}, SecondaryStatus: {}]\".format(\n",
    "                primary_status, secondary_status\n",
    "            )\n",
    "        )\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model training in real-time\n",
    "\n",
    "In the final section, the code will retrieve the tensors from the bottlneck layer and input/output tensors while the model is still training. Once we have the tensors, we will compute t-SNE and plot the results.\n",
    "\n",
    "Helper function to compute stochastic neighbor embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to compute stochastic neighbor embeddings:\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_tsne(tensors, labels):\n",
    "\n",
    "    # compute TSNE\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(tensors)\n",
    "\n",
    "    # add results to dictionary\n",
    "    data = {}\n",
    "    data[\"x\"] = tsne_results[:, 0]\n",
    "    data[\"y\"] = tsne_results[:, 1]\n",
    "    data[\"z\"] = labels\n",
    "\n",
    "    return data\n",
    "\n",
    "#Helper function to plot t-SNE results and autoencoder input/output:\n",
    "def plot_autoencoder_data(tsne_results, input_tensor, output_tensor):\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(\n",
    "        ncols=3, figsize=(30, 15), gridspec_kw={\"width_ratios\": [1, 1, 3]}\n",
    "    )\n",
    "    plt.rcParams.update({\"font.size\": 20})\n",
    "    ax0.imshow(input_tensor, cmap=plt.cm.gray)\n",
    "    ax1.imshow(output_tensor, cmap=plt.cm.gray)\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "    ax0.set_title(\"autoencoder input\")\n",
    "    ax1.set_title(\"autoencoder output\")\n",
    "    plt.title(\"Step \" + str(step))\n",
    "    sns.scatterplot(\n",
    "        x=\"x\", y=\"y\", hue=\"z\", data=tsne_results, palette=\"viridis\", legend=\"full\", s=100\n",
    "    )\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "#Create a trial\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())\n",
    "\n",
    "#Retrieve available steps\n",
    "steps = 0\n",
    "while steps == 0:\n",
    "    steps = trial.steps()\n",
    "    print(\"Waiting for tensors to become available...\")\n",
    "    time.sleep(3)\n",
    "print(\"\\nDone\")\n",
    "\n",
    "print(\"Getting tensors...\")\n",
    "rendered_steps = []\n",
    "\n",
    "#Define the tensors to retrieve\n",
    "label_input = \"convolutionalautoencoder0_input_1\"\n",
    "autoencoder_bottleneck = \"convolutionalautoencoder0_hybridsequential0_dense0_output_0\"\n",
    "autoencoder_input = \"l2loss0_input_1\"\n",
    "autoencoder_output = \"l2loss0_input_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the following code retrieves the tensors and computes t-SNE, and plots the data on a map. \n",
    "\n",
    "The model training ususally takes between 10 nad 15 minutes,, however the tensors produced by the training are continuously emitted to the training S3 bucket. This allows the results of the training to be visualised in real time.\n",
    "\n",
    "In this step we can visualise how the autoencoder output has transformed the input image by passing it through the CNN. We can aslo see the clustering of the classes (numbers 0 throug 9 od f the MNIST dataset), and how the clustering has improved over the training run. Once the model training has completed you should see the visualisation in step 990 has achieved a very good clustering of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.exceptions import TensorUnavailableForStep\n",
    "from smdebug.mxnet import modes\n",
    "\n",
    "\n",
    "loaded_all_steps = False\n",
    "while not loaded_all_steps:\n",
    "\n",
    "    # get available steps\n",
    "    loaded_all_steps = trial.loaded_all_steps\n",
    "    steps = trial.steps(mode=modes.EVAL)\n",
    "\n",
    "    # quick way to get diff between two lists\n",
    "    steps_to_render = list(set(steps).symmetric_difference(set(rendered_steps)))\n",
    "\n",
    "    tensors = []\n",
    "    labels = []\n",
    "\n",
    "    # iterate over available steps\n",
    "    for step in sorted(steps_to_render):\n",
    "        try:\n",
    "            if len(tensors) > 1000:\n",
    "                tensors = []\n",
    "                labels = []\n",
    "\n",
    "            # get tensor from bottleneck layer and label\n",
    "            tensor = trial.tensor(autoencoder_bottleneck).value(step_num=step, mode=modes.EVAL)\n",
    "            label = trial.tensor(label_input).value(step_num=step, mode=modes.EVAL)\n",
    "            for batch in range(tensor.shape[0]):\n",
    "                tensors.append(tensor[batch, :])\n",
    "                labels.append(label[batch])\n",
    "\n",
    "            # compute tsne\n",
    "            tsne_results = compute_tsne(tensors, labels)\n",
    "\n",
    "            # get autoencoder input and output\n",
    "            input_tensor = trial.tensor(autoencoder_input).value(step_num=step, mode=modes.EVAL)[\n",
    "                0, 0, :, :\n",
    "            ]\n",
    "            output_tensor = trial.tensor(autoencoder_output).value(step_num=step, mode=modes.EVAL)[\n",
    "                0, 0, :, :\n",
    "            ]\n",
    "\n",
    "            # plot results\n",
    "            plot_autoencoder_data(tsne_results, input_tensor, output_tensor)\n",
    "\n",
    "        except TensorUnavailableForStep:\n",
    "            print(\"Tensor unavilable for step {}\".format(step))\n",
    "\n",
    "    rendered_steps.extend(steps_to_render)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"\\nDone\")\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/mxnet-1.8-cpu-py37-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
